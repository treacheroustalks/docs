\documentclass[11pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{datetime}
\usepackage{color}
\usepackage{url}
\usepackage{fancyvrb}

\newcommand{\hi}[1]{{\color{red}\em #1\/}\\}
\newcommand{\todo}[1]{\footnote{{\color{red} {\bf TODO:} #1}}}
\newcommand{\ask}[1]{\footnote{{\color{red} {\bf QUESTION:} #1}}}

\setcounter{secnumdepth}{3}
\newcommand{\subsubsubsection}[1]{\paragraph{#1}\mbox{}\\}

\begin{document}
\title{Product Report \\
  ``Treacherous Talks''}
\date{\today\ @ \currenttime}
\author{Dilshod Aliev, Jan Daniel Bothma, Stephan Brandauer,\\
 Andre Hilsendeger, Rahim Kadkhodamohammadi, Xinze Lin,\\
Tiina Loukusa, Erik Timan, Sukumar Yethadka}
\maketitle
\tableofcontents

\abstract{
Treacherous Talks is an implementation of a board game (``Diplomacy'') as a web
service.

The report explains the project and takes a look at the requirements.
The technical details of the solutions chosen, are presented and their choices
motivated. The features that make the project interesting,
failure tolerance, scalability and multiple interfaces are highlighted.
To conclude, some of our relative weaknesses are mentioned.
}

\chapter{Introduction}
Diplomacy is a board game, invented in the 1950s where the goal is to try to
conquer Europe just before WW I. You come close to this goal by talking to the
other players --- by diplomacy --- and making them your allies. And you achieve
it by attack them when they do not expect it.

The game is and was commonly played over distance --- starting with playing by
mail, then email and nowadays over pretty web pages with full-blown map
visualization.

The requirements we were faced with asked for implementation of Diplomacy as a
web service while providing several interfaces to this service. Scalability and
Failure Tolerance were of high priority. \\
Even though a board game is a fun thing to implement, we do think that the most
interesting part of our project is the scalability- and fault tolerance-
engineering.

\chapter{Preliminaries}
\hi{Describe important concepts, acronyms, tools you used in the process, target platforms, etc.}
\ask{regarding Releases, Applications: can we assume erlang-knowledge?}
\section{Releases}
\section{Applications}
\section{Scalability vs. Performance}

\chapter{System Description}
%\hi{System architecture, how it works.
%This is the core of your report, and is therefore most likely the largest section.}

\section{Requirements}

\subsection{Three Interfaces}
The requirement stated that we have to provide three interfaces that expose
the same functionality to the user (the operator is forced to use the
web~interface). Those interfaces are:\\
\begin{enumerate}
\item {\bf Web interface} ---
  The game should be accessible via a modern webbrowser {\em and\/} it should
  use websockets to communicate with the browser.
\item {\bf XMPP interface} ---
  The game should be accessible via a chat client using text based orders.
\item {\bf SMTP interface} ---
  The game should be accessible via sending of emails using text based orders.
\end{enumerate}

\subsection{Scalability}
The system should be scalable. Scalability in this context refers to horizontal scaling where the system should be able to handle more load by simply adding more nodes. No further explanations were provided regarding this feature, but since we saw it as a challenge we invested a lot of work into it.

\subsection{Fail-Safety}
The system should be highly available. We interpreted this by assuming that we
should handle hardware failure of physical machines. As with scalability, we
might have been able to get away with less work but this feature as well was
too interesting too resist focusing on it.

\subsection{Websockets}
Websockets are a tcp-like connection between a browser and a webserver.
Their novelty is that they are not implemented by polling which makes them quite
fast.
They can be used to send javascript that updates only parts of the client page
instead of reloading a page and are a great tool to shift computing to the
client side.

The websockets feature was mostly an issue because of the tool support (or lack
thereof) we were faced with. More is explained in Sec.~\ref{sec:frontends}.
Otherwise, websockets are an amazing technology and as will have a great impact on
web development in the future since tool support is increasing.

\subsection{AI}
Writing a simple AI was a requirement which interested us as well. However, we
were stuck in a tradeoff because time was limited: fail-safety+scalability
vs.\ AI players. In combination with our customer, we agreed on focusing on the
performance characteristics and leaving the AI players for future work.

\section{Architecture}
\subsection{Overview}
\todo{How modules communicate with each other}
% http://redmine.pcs/projects/dip/wiki/Communication

\begin{figure}[h]
 \centering
 \includegraphics[width=13cm]{./graphics/arch.pdf}
 \caption{A possible cluster.}
 \label{fig:arch}
\end{figure}

Our Architecture is divided in three main blocks, the {\em frontends}, the
{\em controller}, and the {\em backends}. In Fig.~\ref{fig:arch} a running
cluster as it could be configured is shown. {\em server 1} shows a full
configuration as it includes all three frontends, a backend and riak. Riak, our
database is explained in sec.~\ref{sec:riak}.
The operator, however, is free to choose to only run a specific selection of
these and can combine them freely.

The responsibilities are not surprising: the frontends receive user input and
transform the input into messages which are sent to the controller.
The controller filters out illegal messages according to the session database
and the user privileges before handing them off to the backends --- which will
respond with an answer.

\subsubsection{Modularity --- and its Relation to Scalability}
One thing that is not immediately visible in our architecture is the fact that
the individual modules are very independent of each other. Even though the
architecture graphic shows a complete example of a running cluster, we can
choose to run some modules alone. \\
If we would, for example, find out that our system is slow because the
web~frontend is the bottleneck, we could add more servers to the cluster that
run only a web~frontend (see Fig.~\ref{fig:arch}, ``Server n-1'').
A controller, however is mandatory, since in our implementation, the controller
is responsible for starting the other applications.
We can do the same with each frontend types, with backends and with riak nodes.
Our architecture, therefore, inherently supports scaling out very well.
Since the frontends are not depending on each other at all, we did not spend
resources on load testing them --- we needed that
time to benchmark and load test our backends and riak nodes.

\subsubsection{Process groups}
\label{sec:process_groups}
The system uses process groups to provide load balancing by distributing work
across nodes.
This is done by each process in the backend joininng the process group for its
application. A calling process can then use the process groups to find a
process to call. The selection is done semi-randomly, if there is not a local
process to call, a random process is used out of that group.
Work is then distributed across the running nodes and prevents one node from 
receiving all calls. But, as it is done randomly it does not guarantee equal
distribution, but during load testing we didn't see that the random selection
caused any bottlenecks.

\subsubsection{Stateless design}
One of the ways to scale a system is to use a shared nothing (SN) architecture
where every node is self-sufficient and the system has no single bottleneck.
This allows for a distributed system that is both scalable and fault tolerant.
The implementation of a SN architecuture adds a constraint that individual
nodes can only have state that could be lost or must be stateless.

With this in mind, our architecture was designed to allow applications to
be distributed across the physical machines in various configurations
(see Fig.~\ref{fig:arch}). All the system state is moved to the database
and some nodes that have state can be restored from the database, in
the event of failure.

We did have to use state in certain parts of the system due to the
distributed nature of the application. Briefly, the parts of the system
with state and the reasoning behing them are,

\begin{itemize}
\item Game timer --- A game has various events associated with it and
tracking these events with time needs a process with a certain amount
of state.
\item Game join process --- Requests from multiple users joining the same
game needs to be serialized to avoid concurrency issues.
\item User session --- Multiple requests from the same user needs to be
ordered since without the ordering the requests can arrive at the backend
at different times creating inconsistent data.
\end{itemize}

\subsection{Frontends}
\label{sec:frontends}
The frontends speak almost the same language to the user, which made the
implementation of front-end logic very generic.

\subsubsection{Web}
The web frontend is running Yaws as a web server.
After deciding to use nitrogen as a web framework, we had to drop nitrogen 
because of the websockets requirement for reasons detailed below.
Yaws is configured as a ``/" application module (appmod) so that we can have a
single entry point for handling all the requests. Server side includes (ssi) are
also used to load static content via ajax.

The web frontend relies heavily on javascript since it contains a good part of the application logic handling user interactions, requests, responses and game functionalities. We also use the toolkit Bootstrap\cite{bootstrap} for the user interface which allows us to quickly develop clean pages.\\
\todo{Karl: ``what are clean pages?''}

We had the option to extend Nitrogen to support websockets, but after spending
some time investigating the possibility and walking through the code to
understand it properly, we came to the conclusion that it would be a project on
its own to do that. Nitrogen uses SimpleBridge which provides a standardized
interface to all its supported web servers. We found that adding websockets
would mean to change/add a lot of code, in a lot of modules, the way
Nitrogen/SimpleBridge is structured. Instead, as previously mentioned, the web
frontend is using plain javascript, which is very convenient for creating a
websocket connection.

Throughout the course of the project the websocket handshake protocol has
been changing.
Not until the end of the project has a protocol (RFC 6455) been released that
has been proposed to be the official standard, we did not have the resources
to update our system whenever a new version was released. Instead, a decision
on what version to support had to be made in the beginning of the project, so we
could focus developing our product.
It would influence what webserver to use and which web browser to support. We
chose the ``hybi-10'' version of the protocol --- this is the version, Yaws and
Chromium 14 implement. 
\todo{JD: correct if inaccurate or fix if Yaws is updated}

\subsubsection{XMPP}
Using ejabberd as XMPP server was an obvious choice since ejabberd is the
standard solution for XMPP servers and ejabberd is implemented
in Erlang which led us to hope that it would play well with our code.

There are three ways to implement integration with ejabberd.

\begin{itemize}
\item Client - A bot that uses an Erlang client such as exmpp can be used to
connect to the server.
All users send messages to the bot via the ejabberd server. e.g. bot@example.com
An issue jabber client is that it doesn’t scale. Using a single bot will mean
all the users will have to be in the bot’s roster (user list). ejabberd doesn’t
handle the scaling of rosters very well (known to fail for clients > 40k).
\item Component - A component is a trusted piece of an XMPP server that can send
and receive arbitrary stanzas.
In other words, we can add a module to ejabberd and define a virtual domain to
get all messages that are sent to this domain.
Because the name of a component is a domain (example: tt.localhost), a component
can pretend to be many users.
Any stanza addressed to service@tt.localhost will be delivered to tt.localhost
no matter what the value is of 'service'.
\item S2S(server to server) - This is the next step for those who need very
large scale. This was not suitable for us since it requires us to learn a new
protocol and is most possibly not necessary for our needs.
\end{itemize}

We decided to use component to communicate with users. We added a module to
ejabberd that registers a hook to get all the messages that are sent to
tt.localhost and forwards it to our backend. ejabberd automatically spawns a
new process for a new user who sends message to this component.
If we need to communicate with a user, we use the corresponding process.

In this way, not only users that have an account on our ejabberd server, but
also users that have account on any XMPP server can send their commands to the
specified address and use our system.

\subsubsection{SMTP}
SMTP, together with POP and IMAP are the three most prevalent protocols for
today's email servers.
SMTP is used for sending emails from clients to servers while POP or IMAP
are used for retrieving email from servers to clients.
For our email server, we found three quilified candidates: Erlmail, gen\_smtp
and erlang-smtp.
At first sight, Erlmail seemed to be the most competitive one since it 
supports all these three protocols when others support only one or two of them.
However, since our SMTP frontend doesn't directly talk to email clients, we
figured out that there's no need for email retrieving mechanism for our
servers. Therefore, we picked gen\_smtp server as our SMTP frontend since all
of its modules are only focused on SMTP. In our system architecture, the
SMTP~frontend is the bridge between client side and the backend
(see Fig.~\ref{fig:smtp_arch}).
Once the SMTP frontend receives an email from the client side, it will extract
the email content and pass it to the backend controller. The controller will
interpret and execute the valid orders carried by the email content, then
respond to client side through the SMTP frontend again.

\begin{figure}[h]
 \centering
 \includegraphics[width=5cm]{./graphics/smtp_arch.pdf}
 \caption{Communication between client side and backend.}
 \label{fig:smtp_arch}
\end{figure}

\subsection{Controller}
The main characteristic distinguishing requests is whether they belong to a
session or not.
So the controller has two kinds of workers.
Those responsible for requests with a session and those for requests without.

\begin{figure}[h]
 \centering
 \includegraphics[width=10cm, angle=-90]{./graphics/Concurrency_-_session_proc.pdf}
 \vspace{-1cm}
 \caption{Controller flow of a request with/without session.}
 \label{fig:controller:session_proc}
\end{figure}

The simple ones without sessions are completely stateless and can handle requests from any user.
A fixed number of them is spawned on startup and will handle requests on
arrival.
Their main responsibilities are registration, login and the like.
Figure~\ref{fig:controller:session_proc} illustrates this.

\subsubsection{Session Management}
The session management consists of a group of processes and a mnesia table.
Each session spawns its own session process and writes an entry into the mnesia
table, so that one such process exists for each logged in user.
The mnesia table is necessary to have a mapping between users and sessions.
The processes handle all requests for their session and have the session data
(user data, knowledge of how to push events to the frontend, etc).
The reasons for that are concurrency issues
(more on that in \ref{sec:concurrency}).


\subsubsection{Access Control}
What users can perform what actions on the system is defined by a set of
identities known as roles. The system has four roles.

\begin{itemize}
\item User --- registered member of the system who can create and play games.
\item Blacklisted user --- a user who has been removed from the system.
\item Moderator --- a user with enhanced privileges to moderate games and help
other users.
\item Operator --- an administrator who has complete control over the system.

\end{itemize}


\subsection{Riak}
\label{sec:riak}
\todo{reference to explain CAP controls}
The choice of riak as database was a careful one: we evaluated riak, couchDB
and mnesia but riak was our favourite in the end --- its scalability features
are very simple to use and its potential for scalability is what we needed.
Due to consistency issues, we had to resort to using mnesia for sessions and
the game joining processes, as it provides transactions.

Riak proved to be a good choice for us since its performance parameters (called
``CAP controls'' in riak-lingo) are very easy to tune and it is quite well
documented how riak behaves under load. The scalability problems we had
came from using the search module too much.

Riak is a distributed key/value store that connects an arbitrary number of
{\em nodes} to form a cluster. All of these nodes can --- but don't have to ---
run on different machines (and do so in our standard setup). As soon as one
node receives a write for one key/value pair, the node will make sure that the
data is written on a certain number of nodes. That number can be chosen from
$[1 \ldots N]$ where $N$ is the number of nodes.
No node in a riak cluster is privileged, they all have exactly the same
responsibilities which makes the architecture simpler.
The ease of adding nodes to a running riak cluster is one of its main
advantages, data are redistributed in order to achieve fair distribution after
one node is added. This can, of course, have performance implications but they
were not measured by us.

\subsubsection{eleveldb}
Riak's storage backend was a problem. Riak has the feature to switch the
storage backend --- the way, key/value pairs are stored on a node.
We initially used {\tt eleveldb} because it supported secondary indices, a
feature we wanted. However, {\tt eleveldb} showed degrading performance
in our context: the throughput of database operations was decreasing linearly
over time, down to zero. We could not pinpoint the problem, so we had to switch
the storage backend to {\tt bitcask}, riak's standard storage backend.
Bitcask does not support secondary indices, and because of that it was
necessary to use {\tt riak\_search} more --- which led to scalability
issues\ldots

\subsubsection{Mnesia}
A user can access our system from multiple frontends resulting in
concurrency issues. We dealt with them by making sure that the user
can use only one frontend at a time.

Another issue was that multiple orders sent by the same user can arrive at the
backend in a different sequence, thereby creating inconsistent data. This was
fixed by serializing the user's commands.

The implementation of the above two solutions is not possible using Riak since
it is an eventually consistent database. Mnesia, which is distributed and has
transactions, is the right fit.

We use Mnesia to keep track of user sessions. Combining this with
the use of one Erlang process per session makes the implementation complete.


\subsection{Backend}
\subsubsection{Game Managing}
Managing games is split up in two main tasks: {\em game timing\/} and
{\em order-processing}. \\
Game timing is implemented as a {\tt gen\_fsm} that changes states when a game
phase needs to stop, eg.\ when the deadline for handing in orders is over.\\
Before a phase is started, the rules processing is done by a module we call
the ``rule engine'': the orders which were sent by the users before the
deadline are read from the database and passed, along with the current game
map, to the rule engine.
\subsubsection{Messaging}
Since communication is very important in the game --- some even say, that the
game is mostly about communication --- the messaging module is a very central
feature for us. We support two types of messages: {\em in-game\/} and
{\em off-game\/}-messages.\\
Messages in game never involve the user nick for tactical reasons: if someone
remembers my nickname, he has an easier time to anticipate my moves since he
will likely remember my actions in last games.
Or, worse: he might still hold a grudge against me. This is why you never
communicate with players in-game by using their nickname, but by using their
country.

Off-game messages on the other hand are sent to a nickname and the recipient
will see the sender's nickname. The basic use case for the off-game messaging
is giving users the chance to set up games for their friends and tell them
about it.
\subsubsection{Search}
Our search module provides the functionality to search, for instance, for
games, based on their properties (like all game parameters). For the
implementation of search, we relied on the riak extension {\tt riak\_search}.

Riak search is a search engine that is tightly coupled with the Riak datastore.
We add a precommit hook so that whenever a new object is added or an old one
updated, the object is indexed (tokenization with standard Lucene analyzers)
and saved.
It provides a rich query language consisting of term searches, field searches,
boolean operators and wildcards to fetch matching objects ordered by relevance.

This feature comes with a price though and should be used with caution.
During load testing we discovered, that it should be avoided for often updated data.
As it has to re-index all fields of an object on every write it can kill the performance.
Therefore we tried minimizing writes on search indexed data and if possible not
to use the riak search feature at all.

\subsubsection{User Management}
The user management module's purpose is to create, update, read, delete users
in or from the database. The implementation is quite short and should contain
few surprises.

\subsection{Concurrency}
% http://redmine.pcs/projects/dip/wiki/Concurrency_handling
\label{sec:concurrency}
\subsubsection{Problem}
Handling concurrency can be quite tricky.
Especially with an eventually consistent database like Riak.
The system is designed so that any node can handle incoming requests,
since it is database driven, and on one node there are multiple workers,
that can perform the same tasks.
Thus two requests involving an update on the same key-value pair can, and will,
end up on different workers or even nodes.
This can lead to inconsistency, because they might have different work load
and execute the tasks out of order.
Figure \ref{fig:concurrency:problem_expl} illustrates this.
\begin{figure}[htbp!]
 \centering
 \includegraphics[width=8cm, angle=-90]{./graphics/Concurrency_-_Earlier_session_write_replace_later_session_write.pdf}
 \vspace{-1cm}
 \caption{First request written after second one, leading to inconsistency.}
 \label{fig:concurrency:problem_expl}
\end{figure}

\begin{figure}[htbp!]
 \hspace{-3cm}
 \includegraphics[width=\textwidth, angle=-90]{./graphics/Concurrency_-_Siblings.pdf}
 \vspace{-4cm}
 \caption{Sibling creation.}
 \label{fig:concurrency:siblings}
\end{figure}
Another problem is shown in Figure \ref{fig:concurrency:siblings}.
Two different nodes might end up writing to the same key without even knowing
there was a concurrent write.
Riak's CAP control specifies how many Riak nodes should respond a positive write
before returning.
In case 2/4 have to respond, two different writes can get the ``ok''.
Our backends would not even know there was a simultaneous write.
Riak tries to automatically resolve this among others with vclocks.
If Riak cannot resolve this it will leave both values as so called siblings
in the database.
It is then up to the backend to resolve the conflict on the next read
and write back the real value.

\subsubsection{Solution}
A common solution for this problem is to serialize requests/writes to the same key.
A sequential execution of tasks will always ensure the correct order and not
create inconsistent data.
In Erlang this is best done with processes.
Each process has a message queue and can only handle one message after another.
Thus requests are serialized if they have to go to the same process.

In our system there are two kinds of interactions that need to be considered:
single user concurrency and multi user concurrency.

\subsubsubsection{Single user concurrency}
Single user concurrency involves all the data that is written by only one user,
like user profile updates and game orders.
In order to serialize these there is one process for each session,
and each user is only allowed to be logged in once at a time.
\begin{figure}[htbp!]
  \centering
 \includegraphics[width=8cm, angle=-90]{./graphics/Concurrency_-_Login.pdf}
 \vspace{-1cm}
 \caption{User login.}
 \label{fig:concurrency:login}
\end{figure}
To ensure only one active session the login has to consider concurrency as well.
Figure \ref{fig:concurrency:login} shows how the login works.
Any old session needs be terminated before we can start a new one.
Also we use mnesia instead of riak to store session information,
as it supports transactions.

Unfortunately this still leaves one case.
For example a user might re-login while his requests to update the profile is
being handled and then tries to update the profile again before the previous
update has been written.
This is very unlikely to happen, as the user needs to do the update very quickly.
However it still needs to be handled.
\begin{figure}[htbp!]
  \centering
 \includegraphics[width=9cm]{./graphics/Concurrency_-_Conflict_resolution_using_session_history.pdf}
 \vspace{-1cm}
 \caption{Siblings resolutions using session history.}
 \label{fig:concurrency:history}
\end{figure}
We use a session history to resolve siblings, which is updated during login.
Additionally we store which session was responsible for the update.
When the backend encounters siblings it then checks the session history which
is the newer one and picks the corresponding value to be the correct one.
Figure \ref{fig:concurrency:history} illustrates this.

\subsubsubsection{Multi user concurrency}
Multi user concurrency involves the data that can be written by multiple users,
like joining or updating a game.
In general we tried to  design our database schema to avoid shared writable data
as much as possible.
For example the game orders for a certain phase could be stored as one value in riak,
instead we keep one value for each player.
This leads to seven reads on phase change, but order writing does not have conflicts.

Nevertheless, we could not avoid it completely.
Multiple users might try to join the same game.
There might be a conflict, if they want to play the same country or only one spot is left.
Besides the creator of the game is no longer allowed to update the game once a player has joined.
Therefore we have a game joining process for every game that has not started yet.
All join and update requests go through that process, thus ensuring consistency.
To ensure only one such process per game we use mnesia due to its transactions.

\section{Code organization}

The project consists of a set of Erlang applications logically grouped
based on their functionalities. We have two more directories at the
project level, one for external tests and the other for the release.

Below is the high level directory structure of the project.

\begin{verbatim}
   |-apps
   |---cluster_manager
   |---controller_app
   |---datatypes
   |---db
   |---game
   |---gen_moves
   |---load_test
   |---message
   |---necromancer
   |---service
   |---smtp_frontend
   |---system_manager
   |---user_management
   |---utils
   |---web_frontend
   |---xmpp_lib
   |-ext_test
   |---bench
   |---fault_tolerance
   |---smtp_integration_test
   |---websocket_client
   |---xmpp_integration_test
   |-rel
\end{verbatim}

Briefly describing the applications,

\begin{center}
    \begin{tabular}{ | l | p{10cm} |}
    \hline
    Application & Description \\ \hline \hline
    cluster\_manager & escript for management of the distributed
    cluster \\ \hline
    controller\_app & The controller application \\ \hline
    datatypes & A central place for common configuration. It contains bucket
    names and records \\ \hline
    db & The database wrapper that handles all the db requests\\ \hline
    game & Contains game logic, game timer, rule engine and other game
    related code \\ \hline
    gen\_moves & Generates moves that can be used for load testing \\ \hline
    load\_test & Code used for load testing \\ \hline
    message & Code used for handling messages \\ \hline
    necromancer & Code used for resurrecting dead VMs \\ \hline
    service &  OTP application library that provides functionality used by
    all service applications \\ \hline
    smtp\_frontend & Handles all the mail communication \\ \hline
    system\_manager & Single point of entry for configuring and controlling
    the whole system on a server. \\ \hline
    user\_management & Handles all user related functions \\ \hline
    utils & Commonly used tools and utilities \\ \hline
    web\_frontend & Code for handling the web frontend, including client
    side code \\ \hline
    xmpp\_lib & Library for handling XMPP communication \\ \hline \hline
    \end{tabular}
\end{center}



Additional notes on the code,

\begin{itemize}
\item General Erlang coding style and conventions were followed.
\item The public API of all the modules has specs and edocs.
\end{itemize}

\newpage
\section{Supervision}
A supervisor in Erlang is a process that supervises processes it has spawned.
The supervisor can spawn new child processes and if one of them would die, it
can act according to its configured restart-policy, for example, it could be
configured to never restart children or alway restart them, independent of the
``cause of death''.\\

Each application (that is not only a library) in our backend and also the
controller have a supervision tree structure that enables an operator to fine
tune the number of workers of each application, it also makes it possible
to inspect the status of applications on each server.

As seen in Fig.~\ref{fig:service_app}, there is one process group
(see \ref{sec:process_groups}) for the application workers, and a ``management''
group. The processes in the worker group are the ones doing the heavy work in an
appllication. The ``manager'' of each application in each node makes it
possible to change the number of workers, it also makes it possible to traverse
the group of managers to be able to get the status of each application on every
node it is running on. The supervisors will always restart its workers if they
die unexpectedly.
\begin{figure}[h]
 \centering
 \includegraphics[width=8cm]{./graphics/Service_Application.png}
 \caption{General supervision structure for applications, double-rings are supervisors}
 \label{fig:service_app}
\end{figure}

The game application's supervision tree is slightly different, as it also has a
number of game timers, which don't belong to a process group as seen in
Fig.~\ref{fig:game_app}. The game timer processes have have their own supervisor
which will restart the processes in case the process would die in an unnatural
way, that is if the game has not yet finished nor been stopped by an operator.
\begin{figure}[h]
 \centering
 \includegraphics[width=10cm]{./graphics/game_Application.png}
 \caption{Supervision tree for the game application}
 \label{fig:game_app}
\end{figure}

\chapter{Treacherous Talks}
\section{The Three Interfaces}
\subsection{HTTP}
The user goes to the landing page, there he finds a link to register which will
display a simple form for him to fill out. After the user is registered, he is
able to log in using the login textfields on the landing page.

After logging in, the user is shown a dashboard page (see Fig.~\ref{fig:dashboard})
 where he is able to search for games, look at the games he is playing in (if any) and
chat with other users in-game or off-game.

\begin{figure}[h]
 \centering
 \includegraphics[width=\textwidth]{./graphics/overviewpage.png}
 \caption{The dashboard page.}
 \label{fig:dashboard}
\end{figure}

The web frontend has several key advantages over the two purely text based
frontends:
\begin{itemize}
\item The user does not need to remember his session id.
\item The user sees a graphical map (generated using a HTML5 canvas),
  see Fig.~\ref{fig:map}.
\item It is easier to enter move orders because possible orders are represented
  as drop-down lists, see Fig.~\ref{fig:orders}.
\end{itemize}

\begin{figure}[h]
 \centering
 \includegraphics[width=10cm]{./graphics/graphicalmap.png}
 \caption{The graphical map.}
 \label{fig:map}
\end{figure}

\begin{figure}[h]
 \centering
 \includegraphics[width=10cm]{./graphics/orderssmall.png}
 \caption{The orders drop-down lists.}
 \label{fig:orders}
\end{figure}

\subsection{XMPP}
Users who log into our XMPP server, will get the address of the component that 
commands should be sent to. If user has an account on any other XMPP servers, 
the commands should be sent to ``service@tt.localhost''. 

If user sends  ``HELP'' or any unknown command to our component, it will return
the list of all valid commands. All commands can be found in appendix
\ref{sec:textbasedcmd}.
Each command starts with the command keyword and must end with ``END'' tag.
All commands and keywords should be entered in capital letters e.g
see appendix \ref{sec:examplecmd}. If the user enters some text before the
command keyword or after the end keyword, they are simply ignored. Users can get
the list of all mandatory fields for each command by sending the command name
and ``END''.

The user will get a unique session ID after logging in. The session ID should be 
stored, because it is necessary for all the future commands.

\subsection{SMTP}
Like most play-by-email games, we enable users to play the game using their own
account from any email service provider.
To connect to our game server, users need to write an email in a required
format(see appendix \ref{sec:examplecmd}),
then send it as an operation request to the email-address of our SMTP frontend
server. After the email is sent, the users will soon receive an email in reply
to their previous request from our game server. To users, the required format
of the email text content is exactly the same as what they use in the XMPP
interface(see appendix \ref{sec:textbasedcmd}), but the difference is that users
are likely to receive replies more instantly in XMPP than in SMTP.

\section{Messages}
In the web frontend, the user is shown two chat boxes: one for off-game chat
and one for in-game-chat (they can be seen --- minimized --- in
fig.~\ref{fig:dashboard}. The user manually has to enter the recipient (in
in-game chat the recipient-country and the game ID). If the recipient is not
online when a message is sent, it will be stored and delivered by the message
application after the recipient logs in the next time. \\
Appendix \ref{sec:textbasedcmd} contains more detailed information on
interaction through the text based interfaces.

\section{Playing}
The web frontend generates drop down lists to make it easier for the user to
enter move orders as shown in Fig.~\ref{fig:orders}. \\
The other two frontends (XMPP and SMTP) take text based orders. Instead of
clicking, the user has to type them and additionally is required to supply
his session ID which he receives after logging in. A dialog between user and
system via XMPP could look like this:

A full list of how to make plays can be found in appendix D.

\chapter{Evaluation and Testing}
%\hi{Describe what experiments you have done to test your product.}
\section{Overview}
We approached testing very seriously from the start and are confident that this
was one of the best decisions we made throughout the project. Unit tests are too
low level to be covered here but they are of course there. We used EUnit for
most of our testing and where generally happy with that choice except for one
thing: EUnit declares a test as failed as soon as it runs for 5 seconds and
there is no central way to change that behaviour. It's possible to do it for
single tests, but the code duplication in that case is, of course, sub-optimal.
That 5 seconds ``feature'' was especially annoying in combination with
continuous integration: our build server was very busy and therefore was
interacting with our database a lot. When several builds were running at the
same time, the database would get slower, therefore pushing tests over the
time-limit, even though they ran perfectly fine on our local machines. Had we
known this issue beforehand, we would have looked more into alternatives of
EUnit.

\section{Integration Tests}
Our integration tests tried to cover everything from the frontends down to the
database. It showed, that the xmpp frontend was the easiest to be tested, so
our tests for smtp- and web-frontend are only testing the basics --- ``it's
there and it reacts'' --- while the xmpp tests send orders, register to the
system, log in, log off, and so on.

\section{Load Tests}
In sprint 4, we started to work on load testing our system. We found it very
hard to get meaningful data from our testruns but even the first, quite informal
load tests resulted in very valuable information.

Load testing was never ran fully automated. Although that would be very useful,
this would have been impossible for us since we would have needed a seperate
cluster to do that and just could not get that amount of hardware.
A smaller automated test on one dedicated machine would have probably helped
already but was not implemented due to time-constraints.

From the start of the load testing, practically no night was unused: tests were
running through the night and were evaluated in the next morning.

It was necessary to write a considerable amount of load-testing-scripts that
distributed our releases across a varying number of nodes, started and connected
them and did the actual load generation. But: the time spent on this was time
spent very well, since it ensured that performance drops because of single
commits were noticed in several instances --- and their cause analyzed.
\todo{include last minute results}
\section{Failure Tests}
Our failure tolerance test starts up a cluster of two backends A and B and starts
a game.
Since we do not know on which backend the game has been started, we halt
backend~A. If fault tolerance works, we can now be sure that the game is on backend~B
(either it was there in the first place or it got restarted there).
We start the backend~A again and then halt backend~B. Now the game gets moved to
backend~A. This way, we can be sure that the game was moved at least once.
If the game continues to run, the test was successful.

\chapter{Related Work}
%\hi{Similarities with existing products/systems. How are you similar and how are you different? What do you do better? What can you learn from what's already out there?

%It is possible that you want to have this section earlier, before the system description, perhaps as a part of (the end of) the product description, so that you can refer to it later.}

Diplomacy has been around since the 1950s and has been played by email, snail
mail and through web browsers. Obviously, we are not going to compare ourselves
to the snail mail solution where a game host receives letters with move orders
from the players and the players send each other letters.

Noteworthy browser based solutions are:\\

\begin{tabular}{lc}
  page                            & registered users \\
  \url{http://webdiplomacy.net}   & 40613 \\
  \url{http://playdiplomacy.com/} & 6849
\end{tabular}
\\
\\The alternative email solutions seem to have even lower user numbers but precise
details are hard to be found. Please note that the numbers in
the table are about {\em registered\/} users, while our benchmarks are in terms
of {\em active\/} users.

The advantages the existing solutions have, are generally better interfaces:
the existing email systems are a bit easier to use since you reference games by
name and not by a number and there is no session ID handling involved.
These issues would be fixable with reasonable resources though. \\
The web interfaces provide better user interfaces as well --- a clickable map
is the norm (click on a unit and then on the target province to issue a move
order, for instance) as well as the timing is handled a bit nicer. They also
provide several game modes (from minor changes to starting units to playing on
a world map). We have the code to handle new maps, but we don't have the map
data. Creating those would be an easy but work-intensive task since you have
to specify all provinces, all connections, starting units, and so on.

Our rules are not perfect yet, they are still a bit rough around the edges but
in probably one or two person weeks would work satisfyingly well.
When it comes to load, we see no problem in handling all web diplomacy
players worldwide (email- and browser-based) with one backend-machine and maybe
more extra frontend machines.

So, in short: to fully catch up with the alternatives, we would need to invest
in bug fixing and user interaction.

\chapter{Conclusions and Future Work}
We are very happy with the work we have done and that the product is, even though
the seemingly endless scope, quite close to being ``ready''.

Despite all this, the work left to be done is considerable:
An AI was in the original requirements but was not delivered due to time constraints.
Bug fixing in the rule engine is necessary. Scalability could be improved by applying
tracing to the cluster which would be lots of interesting work. as well as the
interfaces polished.

In order to make the game playable by the public, a better system to find and join
games would probably be necessary in the web frontend --- and we would need to
do lots of hallway testing and/or maybe publish an alpha version in order to collect
feedback.

One more thing would be to think a lot about security --- not much thought has been
spent on it yet.

The rule engine does not support multi-fleet convoys yet but they are important for
the game tactics (the classic Italian opening called ``lepanto~opening'' uses it, for
instance). This could be done quite easily in the rule engine.

\appendix
\chapter{Installation Instructions}
\section{Requirements}
Treacherous Talks was developed using Erlang/OTP version R14B03 on Ubuntu 11.04
(AMD64). It has not been tested with other versions of Erlang/OTP or other Linux
distributions. Since some of our dependencies, notably Riak, currently doesn't
support Erlang/OTP R15, we have not been able to test the system under that
version of Erlang/OTP.

Since all Erlang-releated packages in Ubuntu 11.04 are out-of-date, we opted for
compiling and installing Erlang/OTP by hand on our development machines. In
general, we recommend that users do this as well since it is the easiest way to
get all of the required parts of Erlang/OTP installed on your system.

We will not provide you with build instructions for the Erlang/OTP distribution,
but under Ubuntu 11.04 you will most likely need the {\tt make}, {\tt gcc}, {\tt
  perl}, {\tt m4}, {\tt ncurses-dev} and {\tt libssl-dev} packages available
before attempting to build it.

Before you can build Treacherous Talks itself, a few extra libraries and tools
need to be present on your machine: \\

\begin{tabular}{lll}
  Name & Version & Ubuntu package name \\ \hline
  libexpat & $>$ 1.95 & libexpat-dev \\
  libxml   & -        & libxml2-dev \\
  libpam   & -        & libpam0g-dev \\
  git      & -        & git \\
  wget     & -        & wget \\
\end{tabular} \\
\\
There are two deployment options regarding the database Riak: running a
standalone Riak installation or distributing it alongside the Treacherous Talks
release package. Here we assume that you want to distribute Riak along with the
release package. This involves building Riak as a part of the system build
process.

In order to build Riak you will need the GNU C++ compiler ({\tt g++}) installed
and the package {\tt libstdc++6-VERSION-dev} where {\tt VERSION} is the current
version in the package repository (in Ubuntu 11.04 {\tt VERSION} is 4.5). For
some reason there are no generic packages any more in Ubuntu, so you need to
specify the version.
\section{Building}
With all dependencies in place, building Treacherous Talks should be
straightforward. First you need to get hold of the source code. The simplest way
is probably to either clone it from Github using git or download a tagged tar
file from the same place. Enter the source code directory.
\todo{Add address to Github repo and tagged tar file}

First we build Riak since we want to distribute it together with the Treacherous
Talks release package. There is support in the Treacherous Talks Makefile for
building Riak, just run {\tt make riak\_release}. This will download, compile
and release Riak. It then moves the release package into the directory {\tt
  system-release} in the top-level source code directory.

Next it's time to build Treacherous Talks. This is done by executing {\tt
  make}. This will invoke the build tool Rebar that is present in the source
code directory. Rebar will download all dependencies and compile everything in
the right order. This step can take a while to complete.

The final two steps after compiling is to make an Erlang release and create a
tarball that contains everything needed to run the system. By executing {\tt
  make release} a release package will be created and placed into the {\tt
  system-release} directory alongside Riak. After this step, we create a tarball
of everything inside that directory with {\tt make tar\_release}. The resulting
tarball is outputted to the {\tt system-release} directory.
\section{Installing from a release tarball}
The resulting tarball from the build step is self-contained and can be freely
moved to other computers running the same version of the operating system. To
install the system, simply extract the tarball to a location of your choice. As
usual in Unix-like systems, take care to have the ownership of the files setup
correctly so that the user running Riak and Treacherous Talks has the correct
permissions on all directories and files. The simplest is to have the user
executing the program owning the files.

If you intend to allow any part of the system to communicate over privileged
ports, ensure that the user has privileges to do so.
\section{Setting up and starting the System Manager}
There is an application called the System Manager in Treacherous Talks. The
purpose of this application is to configure, start and stop Riak and the rest of
the Treacherous Talks system on a single machine. The System Operator uses the
escript called Cluster Manager to interact with a cluster of System Managers via
RPC calls.

\begin{sloppypar}
Before we can start and configure the system we must set up and start the System
Manager itself. There is only one major setting one can change, and that is the
Erlang node name. Enter the directory where the release tarball was extracted.
Edit the file {\tt system-release/tt/etc/nodename.system\_manager} and change
the domain name or ip address as needed (the part after the @-sign). Note that
you must set domain to something externally available if you intend to run the
Cluster Manager on another machine.
\end{sloppypar}

\begin{sloppypar}
When the node name is set, the System Manager is ready to be started. This is
done by proceeding to the directory where the release tarball was extracted and
then executing the command {\tt system-release/tt/bin/system\_manager start} in
a shell.
\end{sloppypar}
\section{Creating a system-wide configuration file}
The main purpose of having both a System Manager and a Cluster Manager is to
simplify the task of configuring and controlling a cluster of nodes running on
different machines. Even if you only run the releases on a single machine, it
simplifies the task of handling the Treacherous Talks system and Riak.

To do this, a single configuration file is used. The file specifies for the
Cluster Manager where the different System Managers are, what releases a single
machine should run and the configuration of such releases. The configuration is
given as a list of host tuples.

Each host tuple describes a host (machine) and contains the domain or ip address
it has, the name of the System Manager and another list of release tuples.

Each release tuple contains a release name (riak, backend, smtp\_frontend,
xmpp\_frontend, web\_frontend), the actual node name for that release and a list
of configuration options. These configuration options correspond exactly to the
ones available in the release configuration file in the {\tt etc} directory of a
release package. Here is a minimal example for running all releases on a single
machine:

\begin{Verbatim}[samepage=true]
[{host, "127.0.0.1", "system_manager",
  [{release, riak, riak,
    [
     {riak_core, [{http, [{"127.0.0.1", 8091}]}]},
     {riak_kv, [{pb_ip, "127.0.0.1"}, {pb_port, 8081}]},
     {riak_search, [{enabled, true}]}
    ]},
   {release, backend, backend,
    [
     {db, [{riak_ip, "127.0.0.1"}, {riak_database_port, 8091},
           {riak_protobuf_port, 8081}]}
    ]},
   {release, smtp_frontend, smtp_frontend, []},
   {release, xmpp_frontend, xmpp_frontend, []},
   {release, web_frontend, web_frontend, []}
  ]}
].
\end{Verbatim}

\begin{sloppypar}
For more information on the available configuration options, please see the
example configuration file in {\tt system\-release/tt/etc/example.config}.
\end{sloppypar}
\section{Using the Cluster Manager}
When the system-wide configuration file is finished, it is time to put it to
use. The Cluster Manager is a small command-line tool (an escript) that reads
the configuration file and connects to running System Managers to enforce the
state given in the configuration file and/or performs a specific action.

The actions performed is controlled by adding switches when invoking the
command. One can use multiple switches to perform more than one action. A short
description of the more common ones follow.

By using the {\tt --setconfig} switch, the Cluster Manager will try to connect
to all specified System Managers and give them the configuration they should
apply. Note that this does automatically apply the configuration to a running
system. To be able to use the new configuration, the system must be restarted.

The {\tt --join} switch is intended to be used whenever a Riak node is added to
the cluster. It will make any new Riak nodes join the already present
nodes. This is only necessary when you add a new node, not after stopping or
starting a Riak node.

Finally, the {\tt --start} and {\tt --stop} switches starts and stops the needed
releases, including Riak if that is needed. To see what releases are running and
responding across a cluster, the {\tt--ping} switch comes handy.

\begin{sloppypar}
To run the Cluster Manager, first go to the directory where the release tarball
was extracted and then execute {\tt system-release/tt/bin/cluster\_manager}. You
also need to supply the name of the configuration file to use and the action to
perform.
\end{sloppypar}
\chapter{Maintenance Instructions}
\todo{Erik}

\chapter{Suggested Future Work}

\chapter{Text based commands}
\label{sec:textbasedcommands}

\section{Playing the game}
The web interface is the only one to provide means to interactively select
orders, but it is also possible to give text based orders as through IM and
email.\\

\subsection*{Writing orders}
Alternative ways to write a move order (also used for retreat orders):
\begin{verbatim}
army warsaw move prussia
a war m pru
a war - pru
a war -> pru
\end{verbatim}
Alternative ways to write a convoy order:
\begin{verbatim}
fleet north_atlantic_ocean convoy army london move norwegian_sea
f nth c a lon m nrg
f nth c a lon - nrg
f nth c a lon -> nrg
\end{verbatim}
Alternative ways to write a hold order:
\begin{verbatim}
army london hold
a lon h
\end{verbatim}
Alternative ways to write a support order:
\begin{verbatim}
army galicia support budapest
a dal s a bud
\end{verbatim}
Alternative ways to write a build order:
\begin{verbatim}
build army munich
b a mun
\end{verbatim}
\newpage

\subsection*{List of provinces and water bodies and their abbreviations}
\begin{tabular}{ l | l | l }
adriatic\_sea - adr & aegean\_sea - aeg & albania - alb \\
ankara - ank & apulia - apu & armenia arm \\
baltic\_sea - bal & barents\_sea - bar & belgium - bel \\
berlin - ber & black\_sea - bla & bohemia - boh \\
brest - bre & budapest - bud & bulgaria - bul \\
burgundy - bur & clyde - bly & constantinople - con \\
denmark - den & eastern\_mediterranean - eas & edinburgh - edi \\
english\_channel - eng & finland - fin & galicia - gal \\
gascony - gas & greece - gre & gulf\_of\_bothnia - bot \\
gulf\_of\_lyon - gol & helgoland\_bight - hel & holland - hol \\
ionian\_sea - ion & irish\_sea - iri & kiel - kie \\
liverpool - lvp & livonia - lvn & london - lon \\
marseilles - mar & mid\_atlantic\_ocean - mid & moscow - mos \\
munich - mun & naples - nap & north\_africa - naf \\
north\_atlantic\_ocean - nat & north\_sea - nth & norway - why \\
norwegian\_sea - nrg & paris - par & picardy - pic \\
piedmont - pie & portugal - por & prussia - pru \\
rome - rom & ruhr - ruh & rumania - rum \\
serbia - ser & sevastopol - sev & silesia - sil \\
skagerrak - ska & smyrna - smy & spain - spa \\
st\_petersburg - stp & sweden - swe & syria - syr \\
trieste - tri & tunis - tun & tuscany - tus \\
tyrolia - tyr & tyrrhenian\_sea - tyn & ukraine ukr \\
venice - ven & vienna - vie & wales - wal \\
warsaw - war & western\_mediterranean & yorkshire - yor \\
\end{tabular}

\newpage
\section{Commands for IM and Mail}
\label{sec:textbasedcmd}
The following commands are available for IM and mail users:

\begin{verbatim}
REGISTER
required: NICKNAME, PASSWORD, EMAIL, FULLNAME
optional: CHANNEL

UPDATE
required: SESSION
optional: PASSWORD, EMAIL, FULLNAME

LOGIN
required: NICKNAME, PASSWORD

LOGOUT
required: SESSION

ORDER
required: SESSION, GAMEID

CREATE
required: SESSION, GAMENAME, PRESSTYPE, ORDERCIRCLE,
          RETREATCIRCLE, GAINLOSTCIRCLE, WAITTIME
optional: PASSWORD, DESCRIPTION, NUMBEROFPLAYERS

RECONFIG
required: SESSION, GAMEID
optional: GAMENAME, PRESSTYPE, ORDERCIRCLE, RETREATCIRCLE,
          GAINLOSTCIRCLE, WAITTIME, PASSWORD, DESCRIPTION,
          NUMBEROFPLAYERS

OVERVIEW
required: SESSION, GAMEID

VIEWCURRENTGAMES
required: SESSION

JOIN
required: SESSION, GAMEID, COUNTRY

SEARCH
required: SESSION
optional: GAMEID, GAMENAME, DESCRIPTION, PRESSTYPE, STATUS,
          ORDERCIRCLE, RETREATCIRCLE, GAINLOSTCIRCLE,
          WAITTIME, NUMBEROFPLAYERS

MESSAGE (in game messages)
required: SESSION, GAMEID, CONTENT
optional: TO

MESSAGE (out of game messages)
required: SESSION, TO, CONTENT

GETPROFILE
required: SESSION

GETPRESENCE
required: SESSION, NICKNAME

REPORTPLAYER
required: SESSION, CONTENT

REPORTISSUE
required: SESSION, CONTENT
\end{verbatim}


The general format to send any command is
\begin{verbatim}
COMMAND
FIELD: <data>
END
\end{verbatim}

where \verb|FIELD| is the name of the field and \verb|<data>| is the
input from the user.


\subsection*{Example commands}
\label{sec:examplecmd}
\begin{verbatim}
REGISTER
NICKNAME: bob
PASSWORD: secret
EMAIL: bob@email.com
FULLNAME: Bob Cat
END

MESSAGE
SESSION: g2dkABFiYWNrZW5kQDEyNy4wLjAuMQAAA+QAAAAAAQ==
GAMEID: 12345
TO: england, france
CONTENT:
Hi! Would you like to help me take down russia?
END
\end{verbatim}

Order writing is done as in the previous section, as content for the
\verb|ORDER| command:
\begin{verbatim}
ORDER
SESSION: g2dkABFiYWNrZW5kQDEyNy4wLjAuMQAAA+QAAAAAAQ==
GAMEID: 12345

army ven -> tri
army tyr support a ven -> tri
END
\end{verbatim}

\end{document}
